{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kütüphanelerin içe aktarılması\n",
    "import yfinance as yf  # Finansal veri indirmek için\n",
    "import numpy as np  # Sayısal işlemler için\n",
    "from sklearn.preprocessing import MinMaxScaler  # Veri ölçeklendirmek için\n",
    "from tensorflow.keras.models import Sequential  # Model oluşturmak için\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout , Activation, BatchNormalization # Model katmanları\n",
    "from tensorflow.keras.callbacks import EarlyStopping , ReduceLROnPlateau # Model eğitimini durdurmak için\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "from sklearn.metrics import mean_squared_error  , mean_absolute_error , r2_score  # Hata ölçümü için\n",
    "import mplfinance as mpf  # Finansal verileri görselleştirmek için\n",
    "import pandas as pd  # Veri işleme için\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensorflow gpu var mı yok mu kontrolü\n",
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Veri Toplama\n",
    "btc_data = yf.download('BTC-USD', period='3600d')  # Bitcoin verilerini yfinance ile indirme\n",
    "#btc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# İndirilen Verileri Mum Çubukları ile Görselleştirme\n",
    "#mpf.plot(btc_data, type='candle', volume=True, style='yahoo', title='BTC-USD') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri Hazırlama\n",
    "btc_df = btc_data[['Open', 'High', 'Low', 'Close' , 'Adj Close', 'Volume']]  # İlgili sütunların seçilmesi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))  # Ölçekleyici tanımlama\n",
    "scaled_data = scaler.fit_transform(btc_df)  # Verilerin ölçeklendirilmesi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Zaman serisi veri seti oluşturma fonksiyonu\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - time_step - 1):\n",
    "        a = dataset[i:(i + time_step), 0:]  # Girdi verileri\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0:])  # Çıktı verileri\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 7  # Zaman adımı\n",
    "X, y = create_dataset(scaled_data, time_step)  # X ve y veri setlerinin oluşturulması\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setini eğitim ve test setlerine ayırma\n",
    "test_size = 300  # Test setinin boyutu\n",
    "train_size = int(len(X) - test_size)  # Eğitim setinin boyutu\n",
    "X_train, X_test = X[0:train_size,:,:], X[train_size:len(X),:,:]  # Eğitim ve test girdileri\n",
    "y_train, y_test = y[0:train_size,:], y[train_size:len(y),:]  # Eğitim ve test çıktıları\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "units1 = 256  # İlk LSTM katmanı için birim sayısı\n",
    "units2 = units1*2  # İkinci LSTM katmanı için birim sayısı\n",
    "units3 = units1  # Yoğun katmanlar için birim sayısı\n",
    "units3 = units1/2  # Yoğun katmanlar için birim sayısı\n",
    "units4 = units3/2  # Yoğun katmanlar için birim sayısı\n",
    "units5 = units4/2  # Yoğun katmanlar için birim sayısı\n",
    "\n",
    "\n",
    "dropout = 0.2  # Dropout oranı\n",
    "batch_size = X_train.shape[0] / 8 # Batch boyutu\n",
    "batch_size = int(batch_size)\n",
    "activation = 'linear'  # Aktivasyon fonksiyonu\n",
    "epochs = 50  # Eğitim sayısı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape=(X_train.shape[1], X_train.shape[2])\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_shape = y_train.shape[1]\n",
    "output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()  # Model oluşturma\n",
    "model.add(LSTM(units1, return_sequences=True, input_shape=input_shape))  # LSTM katmanı\n",
    "\n",
    "\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(LSTM(units2, return_sequences=True))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dropout(dropout))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(units1))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(units3))  # Yoğun katman\n",
    "model.add(Activation(activation))  # Aktivasyon fonksiyonu\n",
    "model.add(Dropout(dropout))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(units4))  # Yoğun katman\n",
    "model.add(Activation(activation))  # Aktivasyon fonksiyonu\n",
    "model.add(Dropout(dropout))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(units5))  # Yoğun katman\n",
    "model.add(Activation(activation))  # Aktivasyon fonksiyonu\n",
    "model.add(Dropout(dropout))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(output_shape))  # Yoğun katman\n",
    "model.add(Activation(activation))  # Aktivasyon fonksiyonu\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error' )  # Model derleme\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 7, 256)            269312    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 7, 256)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 7, 512)            1574912   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 512)            0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 7, 512)            2048      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 256)               787456    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 198       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2679078 (10.22 MB)\n",
      "Trainable params: 2677094 (10.21 MB)\n",
      "Non-trainable params: 1984 (7.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # Model özeti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss',  # İzlenecek metrik\n",
    "                               patience=5,          # Metrikte iyileşme olmadığı durumda kaç epoch bekleyeceği\n",
    "                               verbose=1,           # Eğitim durdurulduğunda bilgi vermesi\n",
    "                               restore_best_weights=True)  # En iyi ağırlıkları geri yükleme\n",
    "# ReduceLROnPlateau callback'ini ayarlama\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.2,  # Öğrenme oranını ne kadar azaltacağı\n",
    "                              patience=3,  # Kaç epoch boyunca iyileşme olmadığında öğrenme oranını azaltacağı\n",
    "                              min_lr=0.001,  # Öğrenme oranının düşebileceği minimum değer\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 0.9755"
     ]
    }
   ],
   "source": [
    "\n",
    "# Modeli Eğitme ve Tahmin Yapma\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test,y_test) , \n",
    "                    epochs=epochs, batch_size= batch_size, \n",
    "                    verbose=1,  \n",
    "                    #callbacks=[early_stopping , reduce_lr],\n",
    "                        )  # Model eğitimi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelin Eğitim ve Test Hata Grafiği\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], label='Eğitim Verisi')\n",
    "plt.plot(history.history['val_loss'], label='Test Verisi')\n",
    "plt.title('Model Hatası')\n",
    "plt.ylabel('Hata')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)  # Test verileri ile modelin performansını ölçme\n",
    "# bu ne  ? yüksek çıkması iyi mi kötü mü ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test).squeeze() # Test verisi üzerinde tahmin yapma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(predictions, columns=['Open', 'High', 'Low', 'Close' , 'Adj Close', 'Volume'])  # Tahminlerin DataFrame'e dönüştürülmesi\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df = pd.DataFrame(y_test, columns=['Open', 'High', 'Low', 'Close' , 'Adj Close', 'Volume'])  # Gerçek değerlerin DataFrame'e dönüştürülmesi\n",
    "y_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = mean_squared_error( predictions , y_test)  # Hata ölçümü\n",
    "MAE = mean_absolute_error( predictions ,y_test)  # Hata ölçümü\n",
    "R2 = r2_score(predictions ,y_test)  # Hata ölçümü\n",
    "print('MSE: ', MSE)\n",
    "print('MAE: ', MAE)\n",
    "print('R2: ', R2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sonuçların Değerlendirilmesi\n",
    "predictions_scaled = scaler.inverse_transform(predictions)  # Tahminlerin ölçeklendirilmesinin tersine çevrilmesi\n",
    "y_test_scaled = scaler.inverse_transform(y_test)  # Gerçek test verilerinin ölçeklendirilmesinin tersine çevrilmesi\n",
    "\n",
    "\n",
    "MSE = mean_squared_error( predictions_scaled , y_test_scaled)  # Hata ölçümü\n",
    "MAE = mean_absolute_error( predictions_scaled ,y_test_scaled)  # Hata ölçümü\n",
    "R2 = r2_score(predictions_scaled ,y_test_scaled)  # Hata ölçümü\n",
    "print('MSE: ', MSE)\n",
    "print('MAE: ', MAE)\n",
    "print('R2: ', R2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_scaled_df = pd.DataFrame(predictions_scaled, columns=['Open', 'High', 'Low', 'Close' , 'Adj Close', 'Volume'])  # Tahminlerin DataFrame'e dönüştürülmesi\n",
    "predictions_scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_scaled_df = pd.DataFrame(y_test_scaled, columns=['Open', 'High', 'Low', 'Close' , 'Adj Close', 'Volume'])  # Gerçek değerlerin DataFrame'e dönüştürülmesi\n",
    "y_test_scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_forecasting(latest_data, time_step):\n",
    "    # Son kullanılabilir verileri al ve ölçeklendir\n",
    "    last_scaled_data = scaler.transform(latest_data)\n",
    "\n",
    "    # Son verileri model girdisi olarak hazırla\n",
    "    X = []\n",
    "    for i in range(len(last_scaled_data) - time_step):\n",
    "        X.append(last_scaled_data[i:i + time_step, 0:])\n",
    "\n",
    "    return np.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future_prices(model, prepared_data, days_to_predict):\n",
    "    predictions = []\n",
    "\n",
    "    # Son verileri kullanarak gelecek günler için tahmin yap\n",
    "    current_batch = prepared_data[-1].reshape(1, prepared_data.shape[1], 6)\n",
    "\n",
    "    for i in range(days_to_predict):\n",
    "        # Tahmin yap ve sonucu sakla\n",
    "        current_pred = model.predict(current_batch)[0]\n",
    "        predictions.append(current_pred)\n",
    "        \n",
    "        # Sonraki tahmin için girdiyi güncelle\n",
    "        current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)\n",
    "\n",
    "    return scaler.inverse_transform(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#btc_data = yf.download('BTC-USD', period='6000d')  # Bitcoin verilerini yfinance ile indirme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_to_predict = 7  # Kaç gün sonrası için tahmin yapılacağı\n",
    "\n",
    "btc_data_son_x = btc_data[-days_to_predict:]\n",
    "\n",
    "\n",
    "#btc_datadan son x günü sil (göz ile test için)\n",
    "btc_data = btc_data[:-days_to_predict]\n",
    "\n",
    "\n",
    "# Son kullanılabilir verileri al (örneğin son 100 gün)\n",
    "latest_data = btc_data\n",
    "\n",
    "# Verileri hazırla\n",
    "prepared_data = prepare_data_for_forecasting(latest_data, time_step=time_step) # Son 100 gündeki verileri kullanarak gelecek 30 gün için tahmin yap\n",
    "\n",
    "# Gelecek x gün için tahmin yap\n",
    "future_predictions = predict_future_prices(model, prepared_data, days_to_predict=days_to_predict) # Son 100 gündeki verileri kullanarak gelecek 30 gün için tahmin yapar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tahmin edilen verileri df yap\n",
    "future_predictions_df = pd.DataFrame(future_predictions, columns=['Open', 'High', 'Low', 'Close' , 'Adj Close', 'Volume'])\n",
    "\n",
    "#btc_datanın son tarihinden başlayarak 30 gün boyunca tarihleri oluştur\n",
    "future_predictions_df['Date'] = pd.date_range(start=btc_data.index[-1], periods=len(future_predictions_df), freq='D')\n",
    "\n",
    "# Tarihi indeks olarak ayarla\n",
    "future_predictions_df.set_index('Date', inplace=True)\n",
    "future_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_data_son_x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
